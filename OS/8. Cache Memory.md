## Chapter 8: Cache Memory

- Cache memory is the most costly but the fastest of all memory types. Cache memory usually lies between CPU and memory. Use to store the data / instructions that are frequently used by the system. It is also used to store the page / segment map tables. 

- For cache memory, the physical address generated by the CPU has two components __(Block number, word in block)__. 


- The three types of cache memory are as follows: __Associative__, __Direct Mapped__, __Set Associative__.

### Associative Cache Memory

- A __tag address__ is compared with the physical address generated for a particular instruction. If there is a match, then that instruction exist in cache memory. If not, the go to main memory fetch the data/instruction and put it in cache memory and save the tag. This tag memory / table work similar to the segment/page map table.

- __Parallel search__ is used to search if the block number exists or has a tag address.

### Direct Mapped Cache:

- Every component in main memory will now have two main components __(Tag, Group)__ including the __byte__ component.

- MM blocks is represented using a multi-dimensional array, in which each component is a block of memory. Each block of memory will belong to one cache line in cache memory which is 256 in size. The columns in the memory block represent a tag and every row represent a group. 

- A memory block number is stored in cache memory directly and the tag number is used to keep in the tag memory. The __valid bit__ says that the corresponding section in cache exists. 

- In the direct mapped cache, there is only a __5-bit comparator__, unlike in Associative cache where there is a comparator for each tag component. 

- Cache miss is more higher in Direct mapped cache since only one particular block of memory can be placed in a specific cache line. In the associate cache, any block can go any available cache line, there, less probability of cache miss. 

### Set Associative cache

- Set associate cache uses a combination of both previous techniques to make the most of the two techniques. 

- In this type of cache setup, instead of having a specific cache line for each memory block, you would have a __set of cache lines__ where the block of memory can go. This will reduce the number of cache misses. This is also referred two as __two-way set associative cache__. The number of sets can be changed and the higher it is the less hits will occur; there is more to compare with.

- In set associative there is a trade-off between the number of misses (higher) and the amount of hardware required (less).

- In this setup (2 sets), there has to be two misses by the comparator to be an actual miss. Conversely, there only needs to be one hit to be considered a hit. 
