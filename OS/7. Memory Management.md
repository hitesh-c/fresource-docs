## Chapter 7: Memory Management


- Base register, limit register

- Address binding - how a program is loads from source code to main memory and the way addresses are generated.
  + Compile time
  + Load Time
  + Execution Time

- Memory Management Unit (MMU) - run-time mapping from virtual addresses to physical addresses.

- Dyamic Loading - routine loading that resides on disk and brought to memory when needed by a process

- Dynamic linking - dyanmically linked libararies (Dll) - could be reused by many processes running; loaded in execution time; can help with disk and memory space since each process doesn't have to load their language library.

- MM Solution - Swapping (moving process temporatily from memory to backing store) - makes it possible for the total physical address of all processes to exceed the real physical memory of the system, thus increasing the degree of multiprogramming in a system.

- The CPU calls the dispatcher when it is ready to execute next process in the ready queue. the dispatcher is in charge of checking if a process is loaded in memory, if it's not and there is not free memory region the dispatcher swaps out a process currently in memory and then swaps in the desired process.

- Swappng rules:
  + never swap a process with pending I/O
  + could be improved if only a portion of a process is swapped.
  + used only when a free memory threshold is exceeded

- An interrupt vector is the memory location of an interrupt handler, which prioritizes interrupts and saves them in a queue if more than one interrupt is waiting to be handled.

- In contiguous memory allocation, each process is contained in a single section of memory that is contiguous to the section containing the next process.


- Memory Allocation strategies:
  + First fit - The first hole in memory that is big enough (faster, space saving, external fragmentation)
  + Best fit - smallest hole that is big enough (space saving, external fragementation)
  + Wirst fit - the largest hole is picked

- Internal fragmentation - is when there is unused memory that is internal to a partition of memory space.

- External fragmentation happens when there is enough total memory (usually in scattered memory partitions) to satisfy a request but its not contiguous. Compaction is a solution (put all free spaces together) - only possible at execution time where addresses can be dynamically relocated.

- Other solution to external fragmentation involves allocation of memory in a random manner, which is achieved by allowing logical addresses of processes to be nonconiguous (segmentation).

- Segmentation - is a memory management scheme where logical address is a collection of segments which include addresses (<segment number, offset>) with segment name and offset within the segment. permits the physical address space of a process to be non-contiguous. still cannot resolve external fragmentation

- paging is a memory management scheme that avoids external fragmentation and the need for compaction. It also solves the proble of fitting memory in chunks of varying sizes onto the backing store (the way swapping does it). Paging might suffer from internal fragmentation.

- A 32-bit CPU uses 32-bit addresses, meaning that a given process space can only be 2^32 bytes (4GB). Therefore, paging lets us use physical memory that is larger than what can be addressed by the CPU's address pointer length.


- Trying to reference a segment beyond the segment limit or before segment limit will cause a trap by the OS. 

- Process Control Block (PCB, also called Task Controlling Block, process table, Task Struct, or Switchframe) is a data structure in the operating system kernel containing the information needed to manage a particular process. The PCB is "the manifestation of a process in an operating system".

- The os maintains a copy of the page table for each process, which is then accessed by the dipatcher. This access increases context-switch time, which is solved using fast registers. Page table is stored in fast registers (each register containg a few pages); too many registers and it is better to use page-table base register (PTBR), which is stored in memory. PTBR allows for quick change in page table since it is just one table, reducing context-switch time. PTBR needs double access to memory. A better solution is translation look-aside buffer (TLB). TLB is associative high speed memory - a fast lookup hardware cache (almost like a key value hash table). TLB stores page number and frame number paired entries. TLB is part of the intruction pipeline and executed as part of it, adding no performance penalty. 


- paging allows for sharing of reentrant code that is allocated in memory through frames. Each process using the reentrant code need only to point to that frame instead of allocating memory to run the same reentrant code.

- Memory protection in a paged environment is done by protecting bits associated with each frame (kept in the table). Bits can be valid-invalid bit.


- page implementation:
  + Hierarchical paging - have outer and inner pages (appropriate for 32 bit systems)
  + Hash page tables - can handle address space larger that 32 bits; uses linked list to store entries
  + Inverted page tables - instead ogf having one table for each process, just have one big table that stores process id to unique idendify the page entry in the page table; it saves storage space but it more time consuming to search the page table.



- __Bare Machine__ - A system in where the designer is to decide how the memory should be addressed. This kind of system is used for dedicated system such as a computer controlling a plant. 

- The typical computer utilizes a __Resident Monitor__, where part of the memory is used by the operating system. In such system, one part of the memory is used by the __operating system__ and the remaining part of the memory is used to load user programs (__User Area__). 

- A user program is not permitted to touch the memory that is used by the Operating System. This is achieved by having a __Fence Address__. The fence address acts a fence or a marker that cannot be surpassed by the user program.

- There are two ways to keep checking if a user program is not surpassing the Fence Address: Software Check or Hardware check. Software check is slow. A hardware solution checks in parallel whether the address generated by the CPU has jumped the Fence Address. If yes, then set a trap, if no then allows for the CPU to use the memory. 

- The problem with the hardware solution is that it is fixed. Meaning that the hardware might not be compatible with an operating system that requires more or less allocated memory. A solution is to use a __Fence Register__ which is reloaded if the operating system is upgraded. 

- Memory can be divided into different areas besides just the o/s and user area. One of the areas called __buffer1__ can be used to swap out jobs (terminate jobs and put them back to secondary storage). The other area called __buffer 2__ can be used to swap in job from a secondary storage into main memory. The other areas (o/s and user) work separately. The user area is now able to take a process that has completed its CPU burst and move it into _buffer 1_. 


- To divide and protect the different memory areas a fence address is also used. A job in buffer 2 does not have to be transferred to user area. The fence address can be shifted up and encompass the area where the job is located (buffer 2) so that the user area can now execute that job. More memory partitions allow for better memory management. 

- __Multiprogramming with Fixed number of Tasks__ - here main memory will partitioned into many fixed segments or areas, including the o/s area. An instruction pointer can be used to make different areas of the memory become active. In this case, a segment must be protected using two registers: A __lower bound register__ and an __upper bound register__. 

- If the CPU process is trying to access an area below the lower bound address and above the upper bound address, then that process is not allocated memory. 

- A __base register__ and a __limit register__ can be used to check if the CPU generated address is requesting to access a part of the memory that is not allowed for that process. If the CPU logical address is less than the limit register, then that logical address is added to the Base address and given access to the physical address in memory. If the logical address is more that the limit address, then is send to a trap. 

- The way the operating system decides where a job is loaded into main memory is based on the fixed size of the partition in memory. 

- __First Fit Algorithm__ - A partition is allocated fully to a job or not based on an algorithm that checks and allocated which is the first segment of the memory that is more than or equal to the size required by the process. Because it is fixed, a partition cannot be allocated to other jobs when a job has been loaded into it. There could be a case where the memory partition allocated to a process is bigger in size than what the process requires. The remaining allocated memory is wasted and also referred to as an __internal fragmentation__.


- __Best Fit Algorithm__ - allocates the memory partition that leads to the minimum internal fragmentation. This means that it has to check _all segments_ in memory to choose the best one for the size required by the process. The complexity of this algorithm is a lot higher than the previous algorithm. 

- There could be a case when the partitions in memory are all smaller in size than what is required by a process. In such scenario, there is a case of __external fragmentation__ because there are free memory partition of which not can be used. 

- A __memory module__ keep track on information about the main memory partition sizes and statuses. 

- The status (Free / Allocated) of each memory partition is kept in what is called a __Partition Allocation Table__.

- Another type of memory management is called __Multiprogramming with Variable number of Tasks__ (MVT). In such case, we don't have a fixed number of partitions. In fact, in MVT, the number and size of partition vary depending on the size requirement from different jobs.  

- In the MVT, initially (no jobs) there will be two partitions in memory: O/S area and User area.

- Assuming we have the following jobs:

```Pascal
// memory size 256K
// initial memory allocation
O/S Partition = 40K
User Partition = 216K

// memory requirements for jobs using a FCFS scheduling
J1 = 60K , 10 time units (CPU burst time)
J2 = 100K, 5 time units
J3 = 30K, 20 time units
J4 = 70K, 8 time units
J5 = 50K, 15 time units
J6 = 60K, 9 time units

// Allocation happens the following way

// J1 allocation
2 Partition: 40K --> 100K
Unallocated Partition : 156K

// J2 Allocation
Partition: 100K --> 200K
Unallocated Partition: 56K

// J3 Allocation
Partition: 200K --> 230K
Unallocated Partition: 26K
```

- No other jobs can be loaded into memory since all of them exceed the size of the remaining partition. The remaining unallocated partition become an external fragmentation. 

- After 5 time units, J2 will complete execution and the partition held by J2 will change its state to unallocated.

```Pascal
O/S Partition: 0 --> 40K

// J1 allocation
2 Partition: 40K --> 100K
Unallocated partition: 100K --> 200K (after J2 released it)

// J3 Allocation
Partition: 200K --> 230K
Unallocated Partition: 26K (230K - 256K)

// J4 Allocation
Partition: 100K --> 170K
Unallocated Partition: 30K (170K - 200K) // this makes two unallocated partitions in memory
```

- After 5 more time units, J1 will complete execution

```Pascal
O/S Partition: 0 --> 40K

Unallocated partition: 60K (40K - 100K) (after J1 released it)

// J4 Allocation
Partition: 100K --> 170K
Unallocated Partition: 30K (170K - 200K) 

// J3 Allocation
Partition: 200K --> 230K
Unallocated Partition: 26K (230K - 256K)

// J5 Allocation
Partition: 40K --> 90K
Unallocated Partition: 10K (90K - 100K)
```

- In the above given scenario, there is a total of 66K of memory which is unallocated. The remaining job only requires 60K. In order to use the remaining memory, all the free unallocated partition can be compacted together contiguously to make a bigger partition (size: 66K). Such technique is called __Memory Compaction__. After memory compaction jobs _J5_, _J4_, _J3_ and _J6_ will occupy a total of 250K memory with a remaining unallocated partition of size 6K.

- In the MVT, two tables are kept: A partition allocation table and a __free area table__ (containing the free unallocated spaces). Free area table contains the size of the area and the starting address of the partition.

- In MVT, you can allow internal fragmentation by merging a very small free area to an already allocated partition. This may avoid some cost.

- Memory compaction is a very costly solution. To come up with a better solution the __Paged Memory Management__ technique was introduced.

- In paged memory management, every process is divided into a number of pages. Processes are divided into a __number of pages__. Memory is divided into a __number of frames__. The page size is the same size as the frame size.

- Any page can be loaded into any of the frames. But there has to be some mapping stating in which frames in memory those pages were loaded. From a frame number it is possible to find out the physical address on the frame in memory where the job pages were allocated. 

- Every pages a _P_ number of bytes (Page size) with a logical address _L_. A logical address has two components: a page number _p_ and an offset/displacement _d_ within that page. This information is stored in a __Page Map Table (PMT)__ Those components are calculated as follows:

```Pascal
// logical address calculation
p = L div P // integer division
d = L mod P

// physical address calculation
Physical address = (f-1) * P + d
```

- Using the paging technique is beneficial because a job's pages can be loaded into memory frames without those frames having to be contiguous as in the previous technique (MFT) or (MVT). This also avoids the problem and complexity of compaction.

- In PMM, there will be internal fragmentation if the page size if (p = L div P) have a remainder. The maximum number of internal fragmentation is equal to (P - 1).

- If a user is trying to access an inaccessible memory frame through a program, the PMT keeps a bit (0/1) that checks if that program page corresponds to that particular requested frame. If the page contains a 0 bit that means there is no corresponding page for that frame.

- In PMM, the __modular structure__ of the program is broken. 

- Instead of having pages, a job is broken down in segments that contain specific modules of the program. Such technique is called __Segmented Memory Management__. 

### Segmented Memory Management (SMM)

- Given the following program with the specific functions of modules:

```Pascal
// functions of different size
Main()
Sqrt()
Factorial()
Billing()
```

- In SMM, the program is broken down to segments, where each segment contain one of the functions or module of that program.

- Each segment is then loaded into memory just as the MVT technique -- with a Base address and Limit address. First, the CPU generates a logical address (s, d) for each segment to be loaded into memory. A __segment memory table__ is needed to map the logical address to the physical address in memory. The offset of the segment cannot exceed the limit address of that segment in memory.

- The first check is comparing if the offset of the segment _d_ is less than limit. If yes, the base is added to the _d_ to set the physical address in main memory. 

- The order of the segments can be implements based on the same order the modules or functions were coded in the program. 

- SMM and PMM can be combined to achieve a new technique called the __Paged Segmented Memory Management__ (PSMM).

- In PSMM, the CPU generates a _(s, d)_ logical address pair for a program. Then _s_ is used to calculate the _limit_ and _PMT Base_ and stored in a __segment table__. Given that _s_ is divided into a number of pages, if _d_ is less that _limit_ then _d_ is broken into two components _(p, d')_. Then add page number _p_ with the _PMT Base_ to give a particular entry within the PMT table of _s_. The entries in _PMT_ contain the frame number _f_ . Lastly, _f_ and _d'_ are used to give the physical address in main memory. 

### Demand Paging (Virtual Memory Management) - Another memory management technique.

- VMM is a paging technique so there will be equal size of frames or segments allocated in main memory to load the program on. 

- In VMM, there is no need to have all the pages loaded into memory at the same time. The instructions of a program can wait for other to execute and the be loaded into main memory when needed. This means that in order for a job to start execution there is no need to load the entire logical space pages of that job into main memory. 

- The following is a flowchart of the way VMM works:

```Pascal
Step 1: Start Processing an Instruction
Step 2: CPU Generate Address
Step 3: Page number is generated
Step 4: Check PMT if Page available in Main Memory

If page in MM:
  Step 5: Fetch the data & compute the instruction
  Step 6: CPU advances to the next instruction
  Step 7: Process continues
Else:
  Step 5: Page fault interrupt is processed 
```

- Process of page fault interrupt:

```Pascal
// Step 5:
Step 1: 
If there is no free block in MM:
  Step 2: Select a page in MM for replacement
  Step 3: Adjust PMT (change bit)
  Step 4: Check if page was modified
  If yes:
    Step 5: Write back into Secondary Storage
  Else:
    Step 6: Free address for the new page
Else:
  Step 2: Get Disk Access of the new page from FMT (File Map Table)
  Step 3: Read in Page
  Step 4: Adjust PMT for new page
  Step 5: Restart the interrupted instruction
  Step 6: Continue processing instructions
```

- There are many page replacement techniques. The simplest technique is called __FIFO (First in First out)__ replacement. The page that was loaded first in memory is the page that is terminated or replaced by the new one. 
 
- Another techniques is called the Optimal replacement technique, where the page being replaced is not needed anytime near in the future. In the case of the FIFO technique, the page being replace might be the page to used next and thus incur a cost (including I/O operation and more page interrupts). __Least Recently Used (LRU)__ replacement techniques is an approximation of the OPTIMAL replacement technique.

- Given a list of page numbers referred to by a user program:

```Pascal
// order of page numbers
7, 0, 1 ,2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1 ,7, 0, 1, 

// three memory frames are available 
[ ]
[ ]
[ ]
```

- FIFO functions as follows:

```Pascal
// page 7 issues a page interrupt and then is loaded into MM
// no page replacement in needed since there is free frame
[7]
[ ]
[ ]

// page 0 is referred, page interrupt, no page replacement
[7]
[0]
[ ]

// page 1 referred, page interrupt, no page replacement
[7]
[0]
[1]

// page 2 referred, page interrupt, yes page replacement using FIFO
[2]
[0]
[1]

// page 0 nothing happens

// page 3 referred, page interrupt, yes page replacement
[2]
[3]
[1]

// page 0
[2]
[3]
[0]

// page 4
[4]
[3]
[0]

// page 2
[4]
[2]
[0]

// page 3
[4]
[2]
[3]

// page 0
[0]
[2]
[3]

// page 3, 2 - nothing happens

// page 1
[0]
[1]
[3]

// page 2
[0]
[1]
[2]

// page 0, 1 

// page 7
[7]
[1]
[2]

// page 0
[7]
[0]
[2]

// page 1
[7]
[0]
[1]
```

- With the above process, two ratios can be calculated: __hit ratio__s and __miss ratio__. 
 
- Hit ratio is the number of hits divided by the number of access (5/20). Miss ratio is (15/20). 

- OPTIMAL function as follows:
```Pascal
// page 7
[7]
[ ]
[ ]

// page 0
[7]
[0]
[ ]

// page 1
[7]
[0]
[1]

// page 2 (replace number of 7 since it needed late on in future)
[2]
[0]
[1]

// page 0 
// page 3 (replace 1)
[2]
[0]
[3]

// page 4
[2]
[4]
[3]

// page 2
// page 3

// page 0
[2]
[0]
[3]
// page 3
// page 2
// page 1
[2]
[0]
[1]

// page 2
// page 0
// page 1
// page 7
[7]
[0]
[1]

// page 0
// page 1
```

- miss ratio (9/20); hit ratio (11/20).

- Least Recently Used (LRU) function as follows:

```Pascal
// page 7 referred
[7]
[ ]
[ ]

// page 0
[7]
[0]
[0]

// page 1
[7]
[0]
[1]

// page 2 (replace with recently used page)
[2]
[0]
[1]

// page 0
// page 3
[2]
[0]
[3]

// page 0
// page 4
[4]
[0]
[3]

// page 2
[4]
[0]
[2]

// page 3
[4]
[3]
[2]

// page 0
[0]
[3]
[2]

// page 3
// page 2
// page 1
[1]
[3]
[2]

// page 2
// page 0
[1]
[0]
[2]

// page 1
// page 7
[1]
[0]
[7]

// page 1
// page 7
// page 0
// page 1
```
- miss ratio (12/20). hit ratio (8/20).

- Overall, _OPTIMAL_ works best and _FIFO_ is the worst algorithm.

- __Locality of reference__ - says that once some data / instruction in accessed, the probability that this data / instruction accessed again is high. This ensures that the pages that are most recently used are not replaced but instead the page that was least recently used. 


- A miss usually includes access to a secondary storage which takes a lot more time what is needed to access the main memory. Hit usually includes access to main memory, therefore, there is efficiency and speed.

- The segmentation table and page map table is put into __cache memory__ because it is constantly being accessed by CPU. It wouldn't be deficient to loaded into main memory since there will always be an extra access to memory upon a mapping of logical address to physical address.

