## Chapter 2.1: Process Scheduling

- **Process scheduling** is also known as CPU scheduling, which is the basis of multiprogrammed operating systems.

- There are two types of scheduling: process scheduling and thread scheduling

- Multiprogramming - to have some process running at all times, to maximize CPU utilization.

- Fundamental idea of CPU scheduling: When a process submits an I/O request, it goes into a WAIT state and so it makes the CPU idle; the idea of multiprogramming is to take away the CPU from that process and give it to another process for execution; this pattern continues;

- Processes alternate between CPU burst (CPU execution) and I/O burst (I/O WAIT).

- I/O bound program - short CPU bursts

- CPU bound program - long CPU bursts

- The above distribution play an important role in selecting an appropriate CPU scheduling algorithm.


- CPU scheduling may happen under the following four circumstances:
	+ 1) Process switches from RUNNING STATE to WAITING STATE (i/o request, wait() child to finish execution)
	+ 2) Process switches from RUNNING STATE to READY STATE (interrupt occurs)
	+ 3) Process switches from WAITING STATE to READY STATE (completion of I/O)
	+ 4) Process terminates

- 1 and 4 are nonpreemptive or cooperative scheduling schemes (only happens when terminating process or switching to WAITING STATE). 2 and 3 are preemptive.

- > The **dispatcher** is the module that gives control of the CPU to the process selected by the short-term scheduler. NOTE: short term scheduler is in charge of moving processes from READY state to ACTIVE or RUNNING state; long-term scheduler is in charge of moving processes from NEW state to READY state.


- Criteria  for choosing CPU scheduling algorithm:
	+ CPU Utilization - make the CPU as busy as possible
	+ Throughput - the number of processes (executing in CPU) per time unit
	+ Turnaround time - the sum of periods spent waiting to get into memory, waiting in the READY queue, executing on the CPU, and doing I/O.
	+ Waiting Time (preemptive - affected by CPU scheduling) - the sum of the periods spent waiting in the READY queue.	
	+ Response time - in contrast to turnaround time, it is the time taken to start responding not the time it takes to output the response.

- It is desirable to maximize CPU utilization and throughput and to minimize turnaround time, waiting time, and response time.

- CPU scheduling algorithm essentially decides which process in the READY queue is to be allocated the CPU for execution.

- **First Come First Serve (FCFS) scheduling** - is nonpreemptive (CPU release happens only when process terminates or upon i/o request); average waiting time varies depending on the order of processes, which usually have different CPU burst times; this scheduling is not appropriate for time-sharing systems, where it is important that each user get a share of the CPU at regular intervals. 

- **Shortest Job First Scheduling (SJF)** - used frequently in long-term scheduling, where the process time limit is used to calculate the length of the next CPU request. With short-term scheduling there is no way to know the length of the next CPU burst; one approach to solve that problem is to use approximation and predicting the CPU burst time of the next process. SJF is preemptive and nonpreemptive.

- **Preemptive SJF scheduling** is sometimes called shortest-remaining-time-first scheduling, where the remaining CPU burst time of the process currently in the CPU is compared with the burst time of the newly arrived process in the READY queue; if new process has less CPU burst time, then the current running process is preempted and the new process is allocated the CPU for execution; for this scheduling algorithm the order of arrival time is also considered; also, a remaining time must be kept

- **Priority scheduling** - The SJF algorithm is an example of the general priority scheduling algorithm; they can be preemptive (if newly arrived process have higher priority than currently running process, it is preempted) and nonpreemptive (put new process at the head of the queue); this algorithm suffers from **indefinite blocking or starvation** (waiting indefinitely for CPU time because of very low priority); a solution to starvation is a concept called **aging** (increase priority based on time waiting).

- **Round Robin Scheduling (RR)** - designed for time-sharing systems; similar to FCFS scheduling but preemption is added to enable context switching between processes; a time quantum is assigned to run processes and interrupts are scheduled (if process CPU burst time exceeds a time quantum) to move to other process once that quantum has passed; this continue until each process has been given enough quantum time to execute fully; when process is preempted it is put back to ready queue; if quantum is high, it may require less context switching; average turnaround time can be improved if process finish their CPU burst in a quantum of 1 unit time; if quantum time is too large then it degenerates to a FCFS policy; a rule of thumb is that 80% of the CPU bursts should be shorter than the time quantum

- **Waiting time** is calculated by subtracting arrival time from visiting time (in case preempted, then visiting time - finished time of last execution before interrupt occurred)
- **Turnaround time** is calculated by adding waiting time and Burst time.

- A **multilevel queue scheduling** partitions the ready queue into several separate queues based on the categories of processes (e.g., foreground (interactive) and background (batch) processes); each separate queue might use different CPU scheduling algorithm; **multilevel feedback queue** allow processes to between queues.

- Thread scheduling - first, user-level threads are scheduled by the thread library to run on an available lightweight process (LWP) using process-contention scope (PCS) (competition among threads within the same process).

- To decide which kernel-level thread to schedule unto a CPU, the kernel uses system-contention scope (SCS) (competition among all threads in the system, regardless of process they belong to).

- **Multiprocessor Scheduling**:
	+ **Asymmetric multiprocessing (AMP)** - one approach to CPU scheduling in a Multiprocessor system has all scheduling decisions, I/O processing, and other system activities handles by a single processor. The other processors execute only user code; reduces data sharing since only processor accesses the system data structures
	+ **Symmetric multiprocessing (SMP)** - each processor has it's own process scheduling; ensure that processors not execute the same process; 

- **Processor affinity** - don't allow processes to migrate between processors; might encounter problem (overhead) with invalidating and repopulating cache memory between the processors; soft affinity (may allows process to migrate between processors); hard affinity (doesn't allows processes to migrate between processors)

- **Load balancing** - a scheme to keep the workload evenly distributed across all processors in an SMP system, so as to avoid idle CPU; this scheme defeats the processor affinity; also, only necessary where each processor has its own private queue of eligible processes to execute.

- **multicore processor** - having multiple processor cores on the same physical chip 

- **Real-Time scheduling** - soft real-time scheduling (no guarantee as to when a critical process will be scheduled); hard real-time scheduling (a task must be served by its deadline); event latency occurs from when an event occurs to when it is serviced;

- Two type of latencies affect the performance of real-time systems:
	+ Interrupt latency - the period of time from the arrival of an interrupt at the CPU to the start of the routine that services that interrupt.
	+ Dispatch latency - the amount of time require for the scheduling dispatcher to stop one process and start another; achieved through providing preemptive kernels

- **Real time operating system** - must support a priority based algorithm with preemption to serve process as soon as they are requested to be executed; this algorithm supports soft-real time functionality but not ensure hard real-time functionality.

- Scheduling Algorithm Evaluation:
	+ Analytic (deterministic modeling) - uses the given algorithm and the system workload to produce a formula or exact numbers to evaluate the performance.
	+ Queueing models  are often only approximations of real systems
	+ Simulations - simulate the algorithms using events and random process generation
	+ Implementation - code the actual algorithm and test in on real system